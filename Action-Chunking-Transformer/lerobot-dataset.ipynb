{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of available datasets:\n",
      "['lerobot/aloha_mobile_cabinet',\n",
      " 'lerobot/aloha_mobile_chair',\n",
      " 'lerobot/aloha_mobile_elevator',\n",
      " 'lerobot/aloha_mobile_shrimp',\n",
      " 'lerobot/aloha_mobile_wash_pan',\n",
      " 'lerobot/aloha_mobile_wipe_wine',\n",
      " 'lerobot/aloha_sim_insertion_human',\n",
      " 'lerobot/aloha_sim_insertion_human_image',\n",
      " 'lerobot/aloha_sim_insertion_scripted',\n",
      " 'lerobot/aloha_sim_insertion_scripted_image',\n",
      " 'lerobot/aloha_sim_transfer_cube_human',\n",
      " 'lerobot/aloha_sim_transfer_cube_human_image',\n",
      " 'lerobot/aloha_sim_transfer_cube_scripted',\n",
      " 'lerobot/aloha_sim_transfer_cube_scripted_image',\n",
      " 'lerobot/aloha_static_battery',\n",
      " 'lerobot/aloha_static_candy',\n",
      " 'lerobot/aloha_static_coffee',\n",
      " 'lerobot/aloha_static_coffee_new',\n",
      " 'lerobot/aloha_static_cups_open',\n",
      " 'lerobot/aloha_static_fork_pick_up',\n",
      " 'lerobot/aloha_static_pingpong_test',\n",
      " 'lerobot/aloha_static_pro_pencil',\n",
      " 'lerobot/aloha_static_screw_driver',\n",
      " 'lerobot/aloha_static_tape',\n",
      " 'lerobot/aloha_static_thread_velcro',\n",
      " 'lerobot/aloha_static_towel',\n",
      " 'lerobot/aloha_static_vinh_cup',\n",
      " 'lerobot/aloha_static_vinh_cup_left',\n",
      " 'lerobot/aloha_static_ziploc_slide',\n",
      " 'lerobot/asu_table_top',\n",
      " 'lerobot/austin_buds_dataset',\n",
      " 'lerobot/austin_sailor_dataset',\n",
      " 'lerobot/austin_sirius_dataset',\n",
      " 'lerobot/berkeley_autolab_ur5',\n",
      " 'lerobot/berkeley_cable_routing',\n",
      " 'lerobot/berkeley_fanuc_manipulation',\n",
      " 'lerobot/berkeley_gnm_cory_hall',\n",
      " 'lerobot/berkeley_gnm_recon',\n",
      " 'lerobot/berkeley_gnm_sac_son',\n",
      " 'lerobot/berkeley_mvp',\n",
      " 'lerobot/berkeley_rpt',\n",
      " 'lerobot/cmu_franka_exploration_dataset',\n",
      " 'lerobot/cmu_play_fusion',\n",
      " 'lerobot/cmu_stretch',\n",
      " 'lerobot/columbia_cairlab_pusht_real',\n",
      " 'lerobot/conq_hose_manipulation',\n",
      " 'lerobot/dlr_edan_shared_control',\n",
      " 'lerobot/dlr_sara_grid_clamp',\n",
      " 'lerobot/dlr_sara_pour',\n",
      " 'lerobot/droid_100',\n",
      " 'lerobot/fmb',\n",
      " 'lerobot/iamlab_cmu_pickup_insert',\n",
      " 'lerobot/imperialcollege_sawyer_wrist_cam',\n",
      " 'lerobot/jaco_play',\n",
      " 'lerobot/kaist_nonprehensile',\n",
      " 'lerobot/nyu_door_opening_surprising_effectiveness',\n",
      " 'lerobot/nyu_franka_play_dataset',\n",
      " 'lerobot/nyu_rot_dataset',\n",
      " 'lerobot/pusht',\n",
      " 'lerobot/pusht_image',\n",
      " 'lerobot/roboturk',\n",
      " 'lerobot/stanford_hydra_dataset',\n",
      " 'lerobot/stanford_kuka_multimodal_dataset',\n",
      " 'lerobot/stanford_robocook',\n",
      " 'lerobot/taco_play',\n",
      " 'lerobot/tokyo_u_lsmo',\n",
      " 'lerobot/toto',\n",
      " 'lerobot/ucsd_kitchen_dataset',\n",
      " 'lerobot/ucsd_pick_and_place_dataset',\n",
      " 'lerobot/uiuc_d3field',\n",
      " 'lerobot/umi_cup_in_the_wild',\n",
      " 'lerobot/unitreeh1_fold_clothes',\n",
      " 'lerobot/unitreeh1_rearrange_objects',\n",
      " 'lerobot/unitreeh1_two_robot_greeting',\n",
      " 'lerobot/unitreeh1_warehouse',\n",
      " 'lerobot/usc_cloth_sim',\n",
      " 'lerobot/utaustin_mutex',\n",
      " 'lerobot/utokyo_pr2_opening_fridge',\n",
      " 'lerobot/utokyo_pr2_tabletop_manipulation',\n",
      " 'lerobot/utokyo_saytap',\n",
      " 'lerobot/utokyo_xarm_bimanual',\n",
      " 'lerobot/utokyo_xarm_pick_and_place',\n",
      " 'lerobot/viola',\n",
      " 'lerobot/xarm_lift_medium',\n",
      " 'lerobot/xarm_lift_medium_image',\n",
      " 'lerobot/xarm_lift_medium_replay',\n",
      " 'lerobot/xarm_lift_medium_replay_image',\n",
      " 'lerobot/xarm_push_medium',\n",
      " 'lerobot/xarm_push_medium_image',\n",
      " 'lerobot/xarm_push_medium_replay',\n",
      " 'lerobot/xarm_push_medium_replay_image']\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "import lerobot\n",
    "\n",
    "# List all available datasets\n",
    "print(\"List of available datasets:\")\n",
    "pprint(lerobot.available_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a54900c07dc4e1abbc1bc28c3f901c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of episodes: 50\n",
      "Average number of frames per episode: 400.000\n",
      "Frames per second: 50\n",
      "Robot type: aloha\n",
      "Tasks:\n",
      "{0: 'Pick up the cube with the right arm and transfer it to the left arm.'}\n",
      "Features:\n",
      "{'action': {'dtype': 'float32',\n",
      "            'names': {'motors': ['left_waist',\n",
      "                                 'left_shoulder',\n",
      "                                 'left_elbow',\n",
      "                                 'left_forearm_roll',\n",
      "                                 'left_wrist_angle',\n",
      "                                 'left_wrist_rotate',\n",
      "                                 'left_gripper',\n",
      "                                 'right_waist',\n",
      "                                 'right_shoulder',\n",
      "                                 'right_elbow',\n",
      "                                 'right_forearm_roll',\n",
      "                                 'right_wrist_angle',\n",
      "                                 'right_wrist_rotate',\n",
      "                                 'right_gripper']},\n",
      "            'shape': (14,)},\n",
      " 'episode_index': {'dtype': 'int64', 'names': None, 'shape': (1,)},\n",
      " 'frame_index': {'dtype': 'int64', 'names': None, 'shape': (1,)},\n",
      " 'index': {'dtype': 'int64', 'names': None, 'shape': (1,)},\n",
      " 'next.done': {'dtype': 'bool', 'names': None, 'shape': (1,)},\n",
      " 'observation.images.top': {'dtype': 'image',\n",
      "                            'names': ['height', 'width', 'channel'],\n",
      "                            'shape': (480, 640, 3)},\n",
      " 'observation.state': {'dtype': 'float32',\n",
      "                       'names': {'motors': ['left_waist',\n",
      "                                            'left_shoulder',\n",
      "                                            'left_elbow',\n",
      "                                            'left_forearm_roll',\n",
      "                                            'left_wrist_angle',\n",
      "                                            'left_wrist_rotate',\n",
      "                                            'left_gripper',\n",
      "                                            'right_waist',\n",
      "                                            'right_shoulder',\n",
      "                                            'right_elbow',\n",
      "                                            'right_forearm_roll',\n",
      "                                            'right_wrist_angle',\n",
      "                                            'right_wrist_rotate',\n",
      "                                            'right_gripper']},\n",
      "                       'shape': (14,)},\n",
      " 'task_index': {'dtype': 'int64', 'names': None, 'shape': (1,)},\n",
      " 'timestamp': {'dtype': 'float32', 'names': None, 'shape': (1,)}}\n"
     ]
    }
   ],
   "source": [
    "from lerobot.common.datasets.lerobot_dataset import LeRobotDatasetMetadata\n",
    "\n",
    "repo_id = \"lerobot/aloha_sim_transfer_cube_human_image\"\n",
    "ds_meta = LeRobotDatasetMetadata(repo_id)\n",
    "\n",
    "# Display metadata information\n",
    "print(f\"Total number of episodes: {ds_meta.total_episodes}\")\n",
    "print(f\"Average number of frames per episode: {ds_meta.total_frames / ds_meta.total_episodes:.3f}\")\n",
    "print(f\"Frames per second: {ds_meta.fps}\")\n",
    "print(f\"Robot type: {ds_meta.robot_type}\")\n",
    "print(\"Tasks:\")\n",
    "print(ds_meta.tasks)\n",
    "print(\"Features:\")\n",
    "pprint(ds_meta.features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f8871750a0e4ed9a86a57296ffa0662",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2a4b43a64bc41bc8fff0afdc41e7a26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected episodes: [0, 10, 11, 23]\n",
      "Number of frames selected: 1600\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e657b2ab925947378335dc77cdcbdfaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "817836c4517440448d9a068b825393a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 56 files:   0%|          | 0/56 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d23e9aed5d3242e682c748d99a3109bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of frames: 20000\n"
     ]
    }
   ],
   "source": [
    "from lerobot.common.datasets.lerobot_dataset import LeRobotDataset\n",
    "\n",
    "# Load a subset of episodes\n",
    "dataset = LeRobotDataset(repo_id, episodes=[0, 10, 11, 23])\n",
    "print(f\"Selected episodes: {dataset.episodes}\")\n",
    "print(f\"Number of frames selected: {dataset.num_frames}\")\n",
    "\n",
    "# Load the entire dataset\n",
    "dataset = LeRobotDataset(repo_id)\n",
    "print(f\"Number of frames: {dataset.num_frames}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0: 0 to 400\n",
      "camera_keys: ['observation.images.top']\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([3, 480, 640])\n"
     ]
    }
   ],
   "source": [
    "# Access frames by episode number\n",
    "episode_index = 0\n",
    "from_idx = dataset.episode_data_index[\"from\"][episode_index].item()\n",
    "to_idx = dataset.episode_data_index[\"to\"][episode_index].item()\n",
    "print(f\"Episode {episode_index}: {from_idx} to {to_idx}\")\n",
    "\n",
    "# Access image frames from the first camera\n",
    "print(f'camera_keys: {dataset.meta.camera_keys}')\n",
    "camera_key = dataset.meta.camera_keys[0]\n",
    "frames = [dataset[idx][camera_key] for idx in range(from_idx, to_idx)]\n",
    "\n",
    "# Print frame type and shape\n",
    "print(type(frames[0]))\n",
    "print(frames[0].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['observation.images.top', 'observation.state', 'action', 'episode_index', 'frame_index', 'timestamp', 'next.done', 'index', 'task_index'])\n",
      "torch.Size([14])\n",
      "torch.Size([14])\n",
      "tensor(4.)\n",
      "tensor(200)\n"
     ]
    }
   ],
   "source": [
    "pprint(dataset[200].keys())\n",
    "print(dataset[200]['observation.state'].shape)\n",
    "print(dataset[200]['action'].shape)\n",
    "print(dataset[200]['timestamp'])\n",
    "print(dataset[200]['frame_index'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Timestamp-Based Frame Selection, not recommended in ACT paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d09b57b9c24463f8bcbc540cea8adfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c046972d3cbf4e548ae172bb0fcab335",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 56 files:   0%|          | 0/56 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaa7f31ae53d45eb9a37e172d0e24ca3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset[0][camera_key].shape=torch.Size([4, 3, 480, 640])\n",
      "dataset[0]['observation.state'].shape=torch.Size([6, 14])\n",
      "dataset[0]['action'].shape=torch.Size([64, 14])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "delta_timestamps = {\n",
    "    # loads 4 images: 1 second before current frame, 500 ms before, 200 ms before, and current frame\n",
    "    camera_key: [-1, -0.5, -0.30, 0],\n",
    "    \"observation.state\": [-1.5, -1, -0.5, -0.20, -0.10, 0],\n",
    "    \"action\": [t / dataset.fps for t in range(64)],\n",
    "}\n",
    "\n",
    "dataset = LeRobotDataset(repo_id, delta_timestamps=delta_timestamps)\n",
    "print(f\"{dataset[0][camera_key].shape=}\")  # (4, c, h, w)\n",
    "print(f\"{dataset[0]['observation.state'].shape=}\")  # (6, c)\n",
    "print(f\"{dataset[0]['action'].shape=}\\n\")  # (64, c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch[camera_key].shape=torch.Size([1, 3, 480, 640])\n",
      "batch['observation.state'].shape=torch.Size([1, 14])\n",
      "batch['action'].shape=torch.Size([1, 14])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    num_workers=1,\n",
    "    batch_size=1,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "for batch in dataloader:\n",
    "    print(f\"{batch[camera_key].shape=}\")  # (1, 4, c, h, w)\n",
    "    print(f\"{batch['observation.state'].shape=}\")  # (1, 5, c)\n",
    "    print(f\"{batch['action'].shape=}\")  # (1, 64, c)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\n"
     ]
    }
   ],
   "source": [
    "print(len(dataloader))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
